{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ales/dev/repos/ai-audio-books\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ales/dev/python-venvs/ai-audio-books/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from httpx import Timeout\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import data.samples_to_split as samples\n",
    "\n",
    "from src.lc_callbacks import LCMessageLoggerAsync\n",
    "from src.schemas import AudioOutputFormat, TTSParams, TTSTimestampsResponse, TTSTimestampsAlignemnt\n",
    "from src.text_split_chain import create_split_text_chain\n",
    "from src import tts\n",
    "from src.utils import GPTModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split text into character phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = samples.GATSBY_2\n",
    "text = \"\"\"\\\n",
    "Margaret: hello, how are you Tom?\n",
    "Tom: nice, thanks. And you?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 00:57:14,451 [INFO] audio-books (lc_callbacks.py): call to gpt-4o with 2 messages:\n",
      "{'role': 'system', 'content': 'you are provided with the book sample.\\nplease rewrite it and insert xml tags indicating character to whom current phrase belongs.\\nfor example: <narrator>I looked at her</narrator><Jill>What are you looking at?</Jill>\\n\\nNotes:\\n- sometimes narrator is one of characters taking part in the action.\\nin this case use narrator\\'s name (if available) instead of \"narrator\"\\n- if it\\'s impossible to identify character name from the text provided, use codes \"c1\", \"c2\", etc,\\nwhere \"c\" prefix means character and number is used to enumerate unknown characters\\n- all quotes of direct speech must be attributed to characters, for example:\\n<Tom>“She’s a nice girl,”</Tom><narrator>said Tom after a moment.</narrator>\\nmind that sometimes narrator could also be a character.\\n- use ALL available context to determine the character.\\nsometimes the character name becomes clear from the following phrases\\n- DO NOT include in your response anything except for the original text with character xml tags!!!\\n'}\n",
      "{'role': 'human', 'content': 'Here is the book sample:\\n---\\nMargaret: hello, how are you Tom?\\nTom: nice, thanks. And you?\\n'}\n",
      "2024-10-31 00:57:15,401 [INFO] httpx (_client.py): HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-10-31 00:57:15,403 [INFO] audio-books (lc_callbacks.py): raw LLM response: \"<Margaret>hello, how are you Tom?</Margaret><Tom>nice, thanks. And you?</Tom>\"\n"
     ]
    }
   ],
   "source": [
    "chain = create_split_text_chain(llm_model=GPTModels.GPT_4o)\n",
    "# chain = create_split_text_chain(llm_model=GPTModels.GPT_4_TURBO_2024_04_09)\n",
    "with get_openai_callback() as cb:\n",
    "    res = chain.invoke({\"text\": text}, config={\"callbacks\": [LCMessageLoggerAsync()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tom', 'Margaret']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Margaret>hello, how are you Tom?</Margaret><Tom>nice, thanks. And you?</Tom>\n"
     ]
    }
   ],
   "source": [
    "print(res.text_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CharacterPhrase(character='Margaret', text='hello, how are you Tom?'),\n",
       " CharacterPhrase(character='Tom', text='nice, thanks. And you?')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margaret: hello, how are you Tom?\n",
      "Tom: nice, thanks. And you?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res.text_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters: ['Tom', 'Margaret']\n",
      "--------------------\n",
      "[Margaret] hello, how are you Tom?\n",
      "[Tom] nice, thanks. And you?\n"
     ]
    }
   ],
   "source": [
    "print(res.to_pretty_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM usage:\n",
      "\n",
      "Tokens Used: 278\n",
      "\tPrompt Tokens: 253\n",
      "\tCompletion Tokens: 25\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0008825\n"
     ]
    }
   ],
   "source": [
    "print(f'LLM usage:\\n\\n{cb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map characters to voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.select_voice_chain import VoiceSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 00:58:58,926 [INFO] audio-books (select_voice_chain.py): reading voice data from: \"data/11labs_available_tts_voices.reviewed.csv\"\n",
      "2024-10-31 00:58:58,933 [INFO] audio-books (select_voice_chain.py): df.shape=(34, 15)\n",
      "2024-10-31 00:58:58,935 [INFO] audio-books (select_voice_chain.py): filtering df by \"manual_quality_review\" column\n",
      "2024-10-31 00:58:58,937 [INFO] audio-books (select_voice_chain.py): df.shape after filtering voices: (25, 15)\n"
     ]
    }
   ],
   "source": [
    "vs = VoiceSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = vs.create_voice_mapping_chain(llm_model=GPTModels.GPT_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  charater_props: ChatPromptTemplate(input_variables=['characters', 'text'], input_types={}, partial_variables={'available_genders': '\"female\", \"male\"', 'available_age_groups': '\"middle_aged\", \"young\", \"old\"', 'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"$defs\": {\"CharacterProperties\": {\"properties\": {\"gender\": {\"title\": \"Gender\", \"type\": \"string\"}, \"age_group\": {\"title\": \"Age Group\", \"type\": \"string\"}}, \"required\": [\"gender\", \"age_group\"], \"title\": \"CharacterProperties\", \"type\": \"object\"}}, \"properties\": {\"character2props\": {\"additionalProperties\": {\"$ref\": \"#/$defs/CharacterProperties\"}, \"title\": \"Character2Props\", \"type\": \"object\"}}, \"required\": [\"character2props\"]}\\n```'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['available_age_groups', 'available_genders', 'format_instructions'], input_types={}, partial_variables={}, template='You are a helpful assistant proficient in literature and psychology.\\nOur goal is to create an audio book from the given text.\\nFor that we need to hire voice actors.\\nPlease help us to find the right actor for each character present in the text.\\n\\nYou are provided with the text split by the characters\\nto whom text parts belong to.\\n\\nYour task is to assign available properties to each character provided.\\nList of available properties:\\n- gender: {available_genders}\\n- age_group: {available_age_groups}\\n\\nNOTES:\\n- assign EXACTLY ONE property value for each property\\n- select properties values ONLY from the list of AVAILABLE property values\\n- fill properties for ALL characters from the list provided\\n- DO NOT include any characters absent in the list provided\\n\\n{format_instructions}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['characters', 'text'], input_types={}, partial_variables={}, template='<text>\\n{text}\\n</text>\\n\\n<characters>\\n{characters}\\n</characters>\\n'), additional_kwargs={})])\n",
       "                  | RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x300a2d9d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x300a2ff50>, root_client=<openai.OpenAI object at 0x300793f50>, root_async_client=<openai.AsyncOpenAI object at 0x300a2e180>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), request_timeout=Timeout(connect=4, read=60, write=60, pool=60)), kwargs={'response_format': {'type': 'json_object'}}, config={}, config_factories=[])\n",
       "                  | PydanticOutputParser(pydantic_object=<class 'src.select_voice_chain.AllCharactersProperties'>)\n",
       "                  | RunnableLambda(remove_hallucinations)\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    character2voice: RunnableLambda(get_voices)\n",
       "  })\n",
       "| RunnableLambda(pack_results)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 00:59:29,332 [INFO] audio-books (lc_callbacks.py): call to gpt-4o with 2 messages:\n",
      "{'role': 'system', 'content': 'You are a helpful assistant proficient in literature and psychology.\\nOur goal is to create an audio book from the given text.\\nFor that we need to hire voice actors.\\nPlease help us to find the right actor for each character present in the text.\\n\\nYou are provided with the text split by the characters\\nto whom text parts belong to.\\n\\nYour task is to assign available properties to each character provided.\\nList of available properties:\\n- gender: \"female\", \"male\"\\n- age_group: \"middle_aged\", \"young\", \"old\"\\n\\nNOTES:\\n- assign EXACTLY ONE property value for each property\\n- select properties values ONLY from the list of AVAILABLE property values\\n- fill properties for ALL characters from the list provided\\n- DO NOT include any characters absent in the list provided\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"$defs\": {\"CharacterProperties\": {\"properties\": {\"gender\": {\"title\": \"Gender\", \"type\": \"string\"}, \"age_group\": {\"title\": \"Age Group\", \"type\": \"string\"}}, \"required\": [\"gender\", \"age_group\"], \"title\": \"CharacterProperties\", \"type\": \"object\"}}, \"properties\": {\"character2props\": {\"additionalProperties\": {\"$ref\": \"#/$defs/CharacterProperties\"}, \"title\": \"Character2Props\", \"type\": \"object\"}}, \"required\": [\"character2props\"]}\\n```\\n'}\n",
      "{'role': 'human', 'content': \"<text>\\n<Margaret>hello, how are you Tom?</Margaret><Tom>nice, thanks. And you?</Tom>\\n</text>\\n\\n<characters>\\n['Tom', 'Margaret']\\n</characters>\\n\"}\n",
      "2024-10-31 00:59:30,470 [INFO] httpx (_client.py): HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-10-31 00:59:30,489 [INFO] audio-books (lc_callbacks.py): raw LLM response: \"{\"character2props\": {\"Tom\": {\"gender\": \"male\", \"age_group\": \"middle_aged\"}, \"Margaret\": {\"gender\": \"female\", \"age_group\": \"middle_aged\"}}}\"\n"
     ]
    }
   ],
   "source": [
    "res2 = chain.invoke(\n",
    "    {\"text\": res.text_annotated, \"characters\": res.characters},\n",
    "    config={\"callbacks\": [LCMessageLoggerAsync()]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectVoiceChainOutput(character2props={'Tom': CharacterPropertiesNullable(gender='male', age_group='middle_aged'), 'Margaret': CharacterPropertiesNullable(gender='female', age_group='middle_aged')}, character2voice={'Tom': 'cjVigY5qzO86Huf0OWal', 'Margaret': '8opUN7sGOKbyojnjvNdl'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tom': 'cjVigY5qzO86Huf0OWal', 'Margaret': '8opUN7sGOKbyojnjvNdl'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character2voice = res2.character2voice\n",
    "character2voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CharacterPhrase(character='Margaret', text='hello, how are you Tom?'),\n",
       " CharacterPhrase(character='Tom', text='nice, thanks. And you?')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 01:02:30,721 [INFO] audio-books (tts.py): request to 11labs TTS endpoint with params {'voice_id': '8opUN7sGOKbyojnjvNdl', 'output_format': <AudioOutputFormat.MP3_44100_192: 'mp3_44100_192'>} for the following text: \"hello, how are you Tom?\"\n",
      "2024-10-31 01:02:33,544 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_44100_192 \"HTTP/1.1 200 OK\"\n",
      "2024-10-31 01:02:33,569 [INFO] audio-books (tts.py): request to 11labs TTS endpoint with params {'voice_id': 'cjVigY5qzO86Huf0OWal', 'output_format': <AudioOutputFormat.MP3_44100_192: 'mp3_44100_192'>} for the following text: \"nice, thanks. And you?\"\n",
      "2024-10-31 01:02:34,321 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/cjVigY5qzO86Huf0OWal/with-timestamps?output_format=mp3_44100_192 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "tts_responses = []\n",
    "\n",
    "for phrase in res.phrases:\n",
    "    voice_id = character2voice[phrase.character]\n",
    "    tts_params = params = TTSParams(voice_id=voice_id, text=phrase.text)\n",
    "    response = await tts.tts_w_timestamps(params)\n",
    "    tts_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments = [response.alignment for response in tts_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TTSTimestampsAlignemnt.combine_alignments(alignments=alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>o</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>w</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>r</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>e</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>y</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>o</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>u</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>o</td>\n",
       "      <td>1.045</td>\n",
       "      <td>1.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>m</td>\n",
       "      <td>1.173</td>\n",
       "      <td>1.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>?</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>#</td>\n",
       "      <td>1.533</td>\n",
       "      <td>1.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>n</td>\n",
       "      <td>1.733</td>\n",
       "      <td>1.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>i</td>\n",
       "      <td>1.861</td>\n",
       "      <td>1.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>c</td>\n",
       "      <td>1.977</td>\n",
       "      <td>2.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>e</td>\n",
       "      <td>2.058</td>\n",
       "      <td>2.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>,</td>\n",
       "      <td>2.105</td>\n",
       "      <td>2.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>2.128</td>\n",
       "      <td>2.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t</td>\n",
       "      <td>2.151</td>\n",
       "      <td>2.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>h</td>\n",
       "      <td>2.186</td>\n",
       "      <td>2.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>a</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>n</td>\n",
       "      <td>2.313</td>\n",
       "      <td>2.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>k</td>\n",
       "      <td>2.372</td>\n",
       "      <td>2.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>s</td>\n",
       "      <td>2.430</td>\n",
       "      <td>2.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>.</td>\n",
       "      <td>2.488</td>\n",
       "      <td>2.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td></td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A</td>\n",
       "      <td>2.569</td>\n",
       "      <td>2.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>n</td>\n",
       "      <td>2.615</td>\n",
       "      <td>2.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>d</td>\n",
       "      <td>2.662</td>\n",
       "      <td>2.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td></td>\n",
       "      <td>2.697</td>\n",
       "      <td>2.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>y</td>\n",
       "      <td>2.766</td>\n",
       "      <td>2.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>o</td>\n",
       "      <td>2.801</td>\n",
       "      <td>2.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>u</td>\n",
       "      <td>2.824</td>\n",
       "      <td>2.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>?</td>\n",
       "      <td>2.894</td>\n",
       "      <td>3.033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char  start    end\n",
       "0     h  0.000  0.081\n",
       "1     e  0.081  0.139\n",
       "2     l  0.139  0.174\n",
       "3     l  0.174  0.232\n",
       "4     o  0.232  0.360\n",
       "5     ,  0.360  0.511\n",
       "6        0.511  0.604\n",
       "7     h  0.604  0.650\n",
       "8     o  0.650  0.685\n",
       "9     w  0.685  0.720\n",
       "10       0.720  0.755\n",
       "11    a  0.755  0.789\n",
       "12    r  0.789  0.824\n",
       "13    e  0.824  0.848\n",
       "14       0.848  0.882\n",
       "15    y  0.882  0.906\n",
       "16    o  0.906  0.929\n",
       "17    u  0.929  0.952\n",
       "18       0.952  0.998\n",
       "19    T  0.998  1.045\n",
       "20    o  1.045  1.173\n",
       "21    m  1.173  1.289\n",
       "22    ?  1.289  1.533\n",
       "23    #  1.533  1.733\n",
       "24    n  1.733  1.861\n",
       "25    i  1.861  1.977\n",
       "26    c  1.977  2.058\n",
       "27    e  2.058  2.105\n",
       "28    ,  2.105  2.128\n",
       "29       2.128  2.151\n",
       "30    t  2.151  2.186\n",
       "31    h  2.186  2.244\n",
       "32    a  2.244  2.313\n",
       "33    n  2.313  2.372\n",
       "34    k  2.372  2.430\n",
       "35    s  2.430  2.488\n",
       "36    .  2.488  2.534\n",
       "37       2.534  2.569\n",
       "38    A  2.569  2.615\n",
       "39    n  2.615  2.662\n",
       "40    d  2.662  2.697\n",
       "41       2.697  2.766\n",
       "42    y  2.766  2.801\n",
       "43    o  2.801  2.824\n",
       "44    u  2.824  2.894\n",
       "45    ?  2.894  3.033"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(''.join([x.text for x in res.phrases]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate audio with timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This document is an annotated index of popular articles and important '\n",
      " 'information for improving and adding functionalities to the installed Arch '\n",
      " 'system. Readers are assumed to have read and followed t')\n"
     ]
    }
   ],
   "source": [
    "text = samples.ARCH_WIKI_1[:200]\n",
    "pprint(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\\\n",
    "hello, this is the test when I am voicing 123 different phrases (some in parentheses),\n",
    "with newlines\n",
    "some unreadable characters: #!@%*&\n",
    "LooLLL123\n",
    "how is it??? going!!\n",
    "and some smiles: :))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = TTSParams(\n",
    "    voice_id=\"8opUN7sGOKbyojnjvNdl\",\n",
    "    text=text,\n",
    "    # seed=672\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AudioOutputFormat.MP3_44100_192: 'mp3_44100_192'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.output_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('voice_id', '8opUN7sGOKbyojnjvNdl'),\n",
       " ('text',\n",
       "  'hello, this is the test when I am voicing 123 different phrases (some in parentheses),\\nwith newlines\\nsome unreadable characters: #!@%*&\\nLooLLL123\\nhow is it??? going!!\\nand some smiles: :))\\n'),\n",
       " ('output_format', <AudioOutputFormat.MP3_44100_192: 'mp3_44100_192'>),\n",
       " ('audio_model_id', Ellipsis),\n",
       " ('language_code', Ellipsis),\n",
       " ('voice_settings', Ellipsis),\n",
       " ('seed', 672),\n",
       " ('previous_text', Ellipsis),\n",
       " ('next_text', Ellipsis),\n",
       " ('previous_request_ids', Ellipsis),\n",
       " ('next_request_ids', Ellipsis)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'voice_id': '8opUN7sGOKbyojnjvNdl',\n",
       " 'text': 'hello, this is the test when I am voicing 123 different phrases (some in parentheses),\\nwith newlines\\nsome unreadable characters: #!@%*&\\nLooLLL123\\nhow is it??? going!!\\nand some smiles: :))\\n',\n",
       " 'output_format': <AudioOutputFormat.MP3_44100_192: 'mp3_44100_192'>,\n",
       " 'seed': 672}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 22:55:03,113 [INFO] audio-books (tts.py): request to 11labs TTS endpoint with params {'voice_id': '8opUN7sGOKbyojnjvNdl', 'output_format': <AudioOutputFormat.MP3_44100_192: 'mp3_44100_192'>, 'seed': 672} for the following text: \"hello, this is the test when I am voicing 123 different phrases (some in parentheses),\n",
      "with newlines\n",
      "some unreadable characters: #!@%*&\n",
      "LooLLL123\n",
      "how is it??? going!!\n",
      "and some smiles: :))\n",
      "\"\n",
      "2024-10-29 22:55:06,333 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_44100_192 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = await tts.tts_w_timestamps(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 22:55:07,034 [INFO] audio-books (utils.py): saving to: \"tmp.672.2.mp3\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tmp.672.2.mp3'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.write_audio_to_file('tmp.672.2', params.output_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ales/dev/python-venvs/ai-audio-books/lib/python3.12/site-packages/pydantic/main.py:390: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `str` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `VoiceSettings` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `int` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `str` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `str` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "2024-10-27 21:44:22,111 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_44100_192 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response_raw = await tts.ELEVEN_CLIENT_ASYNC.text_to_speech.convert_with_timestamps(\n",
    "    **params.to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_parsed = TTSTimestampsResponse.model_validate(response_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, this is the test when I am voicing 123 different phrases (some in parentheses),\\nwith newlines\\nsome unreadable characters: #!@%*&\\nLooLLL123\\nhow is it??? going!!\\nand some smiles: :))\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = response_parsed.alignment.text_joined\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.schemas import TTSTimestampsAlignemnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = TTSTimestampsAlignemnt(\n",
    "    characters=list('abc'),\n",
    "    character_start_times_seconds=[0.1, 0.2, 0.3],\n",
    "    character_end_times_seconds=[0.15, 0.25, 0.35],\n",
    ")\n",
    "a2 = TTSTimestampsAlignemnt(\n",
    "    characters=list('def'),\n",
    "    character_start_times_seconds=[0.1, 0.2, 0.3],\n",
    "    character_end_times_seconds=[0.15, 0.25, 0.35],\n",
    ")\n",
    "a3 = TTSTimestampsAlignemnt(\n",
    "    characters=list(\"ghi\"),\n",
    "    character_start_times_seconds=[0.1, 0.2, 0.3],\n",
    "    character_end_times_seconds=[0.15, 0.25, 0.35],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TTSTimestampsAlignemnt.combine_alignments(alignments=[a1, a2, a3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  char  start   end\n",
       "0    a   0.10  0.15\n",
       "1    b   0.20  0.25\n",
       "2    c   0.30  0.35\n",
       "3    d   0.45  0.50\n",
       "4    e   0.55  0.60\n",
       "5    f   0.65  0.70\n",
       "6    g   0.80  0.85\n",
       "7    h   0.90  0.95\n",
       "8    i   1.00  1.05"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44999999999999996"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_start_time_by_char_ix(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_end_time_by_char_ix(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sound effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map spans indices to original text indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_w_effects = \"\"\"\\\n",
    "Hello<effect prompt=\"soft wind blowing\"> - she said softly, gasping the fresh air from the window</effect>\n",
    "What are you next plans?\n",
    "<effect prompt=\"sound of a cars passing by\">Frankly, I don't know. I need more time</effect>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello - she said softly, gasping the fresh air from the window\n",
      "What are you next plans?\n",
      "Frankly, I don't know. I need more time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = re.sub(r'<.+?>', '', text_w_effects)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r'<effect prompt=\\\"(.*?)\\\">(.*?)</effect>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(5, 106), match='<effect prompt=\"soft wind blowing\"> - she said so>,\n",
       " <re.Match object; span=(132, 224), match='<effect prompt=\"sound of a cars passing by\">Frank>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_matches = list(pat.finditer(text_w_effects))\n",
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundEffectSpan(BaseModel):\n",
    "    prompt: str\n",
    "    text_between_tags: str\n",
    "    # indices relative to LLM response\n",
    "    ix_start: int\n",
    "    ix_end: int\n",
    "    # indices relative to origin text passed to LLM\n",
    "    ix_start_orig_text: int\n",
    "    ix_end_orig_text: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = []\n",
    "\n",
    "rm_chars_running_total = 0\n",
    "for m in all_matches:\n",
    "    mstart, mend = m.span()\n",
    "    prompt = m.group(1)\n",
    "    text_between_tags = m.group(2)\n",
    "\n",
    "    ix_start_orig = mstart - rm_chars_running_total\n",
    "    ix_end_orig = ix_start_orig + len(text_between_tags)\n",
    "\n",
    "    spans.append(\n",
    "        SoundEffectSpan(\n",
    "            prompt=prompt,\n",
    "            text_between_tags=text_between_tags,\n",
    "            ix_start=mstart,\n",
    "            ix_end=mend,\n",
    "            ix_start_orig_text=ix_start_orig,\n",
    "            ix_end_orig_text=ix_end_orig,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mlen = mend - mstart\n",
    "    rm_chars_running_total += mlen - len(text_between_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SoundEffectSpan(prompt='soft wind blowing', text_between_tags=' - she said softly, gasping the fresh air from the window', ix_start=5, ix_end=106, ix_start_orig_text=5, ix_end_orig_text=62),\n",
       " SoundEffectSpan(prompt='sound of a cars passing by', text_between_tags=\"Frankly, I don't know. I need more time\", ix_start=132, ix_end=224, ix_start_orig_text=88, ix_end_orig_text=127)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' - she said softly, gasping the fresh air from the window'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text[5:62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Frankly, I don't know. I need more time\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text[88:127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare audio quality for different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This document is an annotated index of popular articles and important '\n",
      " 'information for improving and adding functionalities to the installed Arch '\n",
      " 'system. Readers are assumed to have read and followed t')\n"
     ]
    }
   ],
   "source": [
    "text = samples.ARCH_WIKI_1[:200]\n",
    "pprint(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_base = TTSParams(\n",
    "    voice_id=\"8opUN7sGOKbyojnjvNdl\",\n",
    "    text=\"hello, how are you doing? this is the test aiming to decide which audio quality option to use\",\n",
    "    # text=text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ales/dev/python-venvs/ai-audio-books/lib/python3.12/site-packages/pydantic/main.py:390: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `str` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `VoiceSettings` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `int` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `str` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  Expected `str` but got `ellipsis` with value `Ellipsis` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "2024-10-27 18:16:54,779 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_22050_32 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:16:54,807 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.mp3_22050_32.mp3\"\n",
      "2024-10-27 18:16:56,094 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_44100_32 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:16:56,110 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.mp3_44100_32.mp3\"\n",
      "2024-10-27 18:16:57,444 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_44100_64 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:16:57,472 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.mp3_44100_64.mp3\"\n",
      "2024-10-27 18:16:59,066 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_44100_96 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:16:59,106 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.mp3_44100_96.mp3\"\n",
      "2024-10-27 18:17:00,483 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_44100_128 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:17:00,513 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.mp3_44100_128.mp3\"\n",
      "2024-10-27 18:17:01,877 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=mp3_44100_192 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:17:01,898 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.mp3_44100_192.mp3\"\n",
      "2024-10-27 18:17:03,164 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=pcm_16000 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:17:03,213 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.pcm_16000.wav\"\n",
      "2024-10-27 18:17:04,584 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=pcm_22050 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:17:04,651 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.pcm_22050.wav\"\n",
      "2024-10-27 18:17:05,986 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=pcm_24000 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:17:06,074 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.pcm_24000.wav\"\n",
      "2024-10-27 18:17:07,600 [INFO] httpx (_client.py): HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/8opUN7sGOKbyojnjvNdl/with-timestamps?output_format=pcm_44100 \"HTTP/1.1 200 OK\"\n",
      "2024-10-27 18:17:07,698 [INFO] audio-books (utils.py): saving to: \"data/compare_audio_quality2/compare.pcm_44100.wav\"\n"
     ]
    }
   ],
   "source": [
    "# out_dp = \"data/compare_audio_quality2\"\n",
    "# os.makedirs(out_dp, exist_ok=True)\n",
    "\n",
    "# for audio_format in AudioOutputFormat:\n",
    "#     if audio_format is AudioOutputFormat.ULAW_8000:\n",
    "#         continue\n",
    "\n",
    "#     params = params_base.model_copy(deep=True)\n",
    "#     params.output_format = audio_format\n",
    "\n",
    "#     response_raw = await ELEVEN_CLIENT_ASYNC.text_to_speech.convert_with_timestamps(\n",
    "#         **params.to_dict()\n",
    "#     )\n",
    "#     response_parsed = TTSTimestampsResponse.model_validate(response_raw)\n",
    "\n",
    "#     filepath_no_ext = os.path.join(out_dp, f\"compare.{audio_format}\")\n",
    "#     out_fp = response_parsed.write_audio_to_file(\n",
    "#         filepath_no_ext=filepath_no_ext, audio_format=audio_format\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffprobe version 7.0.1 Copyright (c) 2007-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.0.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "\u001b[0;35m[mp3 @ 0x134724c80] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
      "\u001b[0mInput #0, mp3, from 'data/compare_audio_quality/compare.mp3_44100_64.mp3':\n",
      "  Duration: 00:00:12.56, start: 0.000000, bitrate: 64 kb/s\n",
      "  Stream #0:0: Audio: mp3 (mp3float), 44100 Hz, mono, fltp, 64 kb/s\n"
     ]
    }
   ],
   "source": [
    "!ffprobe data/compare_audio_quality/compare.mp3_44100_64.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-audio-books",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
